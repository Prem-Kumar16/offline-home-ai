{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "539848b4-f0ef-4b3b-854e-bc3b0f0fe357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/venv/lib/python3.10/site-packages (4.56.0)\n",
      "Requirement already satisfied: accelerate in /home/ubuntu/venv/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: torch in /home/ubuntu/venv/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/venv/lib/python3.10/site-packages (4.0.0)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/venv/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/venv/lib/python3.10/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ubuntu/venv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: Pillow in /home/ubuntu/venv/lib/python3.10/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Using cached scikit_learn-1.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence_transformers\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [sentence_transformers]/5\u001b[0m [sentence_transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.1 scipy-1.15.3 sentence_transformers-5.1.0 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate torch datasets sentence_transformers --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ba2eb-5fc2-4044-af3c-d4825bbc2359",
   "metadata": {},
   "source": [
    "# Checking locally trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d582da0b-a4ec-4283-bb0b-62d929dd1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant says:\n",
      "|>\n",
      "Turning off the kitchen light.\n",
      "\n",
      "Home Assistant Command:\n",
      "{\"service\": \"light.turn_off\", \"target_device\": \"light.kitchen\"}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import json\n",
    "\n",
    "model_id = \"./tinyllama-1.1b-lora-final\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"You are 'Al', a helpful AI Assistant that controls the devices in a house. Complete the following task as instructed with the information provided only.\n",
    "The current time and date is 08:12 AM on Thursday March 14, 2024\n",
    "Services: light.turn_off(), light.turn_on(brightness,rgb_color), fan.turn_on(), fan.turn_off()\n",
    "Devices:\n",
    "light.office 'Office Light' = on;80%\n",
    "fan.office 'Office fan' = off\n",
    "light.kitchen 'Kitchen Light' = on;80%;red\n",
    "light.bedroom 'Bedroom Light' = off\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"Turn off the kitchen light\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Prepare chat-formatted prompt\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate model output\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Keep only assistant's message\n",
    "if \"assistant\" in decoded:\n",
    "    decoded = decoded.split(\"assistant\", 1)[-1].strip()\n",
    "\n",
    "# Extract JSON block\n",
    "json_match = re.search(r\"```homeassistant\\s*({.*})\\s*```\", decoded, re.DOTALL)\n",
    "json_block = json_match.group(1) if json_match else None\n",
    "\n",
    "# Print final clean output\n",
    "print(\"Assistant says:\")\n",
    "if json_match:\n",
    "    natural_text = decoded.split(\"```homeassistant\")[0].strip()\n",
    "    print(natural_text)\n",
    "    print(\"\\nHome Assistant Command:\")\n",
    "    print(json_block)\n",
    "else:\n",
    "    print(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57392b2c-48de-47cf-9ef9-977f4ef02649",
   "metadata": {},
   "source": [
    "# Evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90e141e-6920-437e-a10a-f1ecb0928cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples evaluated: 50\n",
      "Exact JSON match accuracy: 100.00%\n",
      "Exact text match accuracy: 0.00%\n",
      "Entity-level accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "# CONFIG\n",
    "MODEL_NAME = \"./tinyllama-1.1b-lora-final\"  \n",
    "DATASET_NAME = \"acon96/Home-Assistant-Requests\"  \n",
    "SPLIT = \"test\"  \n",
    "MAX_SAMPLES = 50  \n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(DATASET_NAME, split=SPLIT)\n",
    "\n",
    "if MAX_SAMPLES:\n",
    "    dataset = dataset.select(range(MAX_SAMPLES))\n",
    "\n",
    "# Load model and tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Helper: Extract system/user/assistant messages\n",
    "def extract_messages(entry):\n",
    "    \"\"\"Extract system, user, assistant messages from list-of-dicts dataset format\"\"\"\n",
    "    system_prompt, user_message, assistant_message = \"\", \"\", \"\"\n",
    "    if isinstance(entry, list):\n",
    "        for msg in entry:\n",
    "            if msg[\"from\"] == \"system\":\n",
    "                system_prompt = msg[\"value\"]\n",
    "            elif msg[\"from\"] == \"user\":\n",
    "                user_message = msg[\"value\"]\n",
    "            elif msg[\"from\"] == \"assistant\":\n",
    "                assistant_message = msg[\"value\"]\n",
    "    return system_prompt, user_message, assistant_message\n",
    "\n",
    "# Helper: Extract JSON from text\n",
    "def extract_json(text):\n",
    "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Helper: Extract entity from JSON\n",
    "def extract_entity(json_obj):\n",
    "    if not json_obj:\n",
    "        return None\n",
    "    # Try \"target_device\" key\n",
    "    if \"target_device\" in json_obj:\n",
    "        return json_obj[\"target_device\"]\n",
    "    # Or nested inside target\n",
    "    if \"target\" in json_obj and \"entity_id\" in json_obj[\"target\"]:\n",
    "        return json_obj[\"target\"][\"entity_id\"]\n",
    "    return None\n",
    "\n",
    "# Evaluation loop\n",
    "exact_json_matches = 0\n",
    "exact_text_matches = 0\n",
    "entity_matches = 0\n",
    "\n",
    "for example in dataset:\n",
    "    # Extract conversation messages\n",
    "    #system_prompt, user_message, assistant_message = extract_messages(example[\"messages\"])\n",
    "    system_prompt, user_message, assistant_message = extract_messages(example)\n",
    "\n",
    "    # Prepare prompt for model\n",
    "    prompt = f\"{system_prompt}\\nUser: {user_message}\\nAssistant:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate model output\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "    model_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract JSON objects\n",
    "    reference_json = extract_json(assistant_message)\n",
    "    predicted_json = extract_json(model_response)\n",
    "\n",
    "    # JSON exact match\n",
    "    if reference_json == predicted_json:\n",
    "        exact_json_matches += 1\n",
    "\n",
    "    # Text exact match (ignores JSON)\n",
    "    if assistant_message.strip() == model_response.strip():\n",
    "        exact_text_matches += 1\n",
    "\n",
    "    # Entity-level match\n",
    "    if extract_entity(reference_json) == extract_entity(predicted_json):\n",
    "        entity_matches += 1\n",
    "\n",
    "# Compute metrics\n",
    "total = len(dataset)\n",
    "print(f\"Total samples evaluated: {total}\")\n",
    "print(f\"Exact JSON match accuracy: {exact_json_matches / total:.2%}\")\n",
    "print(f\"Exact text match accuracy: {exact_text_matches / total:.2%}\")\n",
    "print(f\"Entity-level accuracy: {entity_matches / total:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9778ac-0cf6-4c9d-83f2-7bc96cb95640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversations': [{'from': 'system', 'value': \"You are 'Al', a helpful AI Assistant that controls the devices in a house. Complete the following task as instructed or answer the following question with the information provided only.\\nServices: cover.close_cover(), cover.open_cover(), cover.stop_cover(), cover.toggle(), climate.set_fan_mode(fan_mode), climate.set_humidity(humidity), climate.set_hvac_mode(), climate.set_preset_mode(), climate.set_temperature(temperature), climate.toggle(), climate.turn_off(), climate.turn_on(), fan.decrease_speed(), fan.increase_speed(), fan.toggle(), fan.turn_off(), fan.turn_on(), light.toggle(), light.turn_off(), light.turn_on(rgb_color,brightness), lock.lock(), lock.unlock(), media_player.media_next_track(), media_player.media_pause(), media_player.media_play(), media_player.media_play_pause(), media_player.media_previous_track(), media_player.media_stop(), media_player.toggle(), media_player.turn_off(), media_player.turn_on(), media_player.volume_down(), media_player.volume_mute(), media_player.volume_up(), switch.toggle(), switch.turn_off(), switch.turn_on(), vacuum.pause(), vacuum.return_to_base(), vacuum.start(), vacuum.stop()\\nDevices:\\nfan.bathroom_down 'Fan in downstairs bathroom' = off\\nlight.front_courtyard_homekit 'Front Courtyard Light' = on;mediumorchid (191, 63, 221);80%\\nlight.front_balcony_homekit 'Front Balcony Light' = off;limegreen (46, 211, 85);92%\\nlight.downstairs_master_bedroom_homekit 'Downstairs Master Bedroom Light' = on;mediumspringgreen (12, 234, 173);65%\\nlock.wine_cellar 'Wine Cellar Lock' = locked\\nlight.downstairs_cinema_mqtt 'Downstairs Cinema Light' = off;limegreen (50, 212, 54)\\nvacuum.back_deck_sweeper 'Back deck area cleaner' = cleaning\\ncover.garage 'Garage Blinds' = open\\nmedia_player.sonos_arc 'Sonos Smart Soundbar' = off\\nfan.outdoor_patio 'Outdoor patio fan' = off\\nlight.downstairs_sitting_mqtt 'Downstairs Sitting Room Light' = on;cornflowerblue (95, 131, 222);16%\\nlight.living_room_ceiling 'Living Room Ceiling Light' = off;teal (4, 76, 117);43%\\nlight.kitchen_bookshelf_warm 'Kitchen Bookshelf Warm Light' = on;limegreen (31, 227, 40);22%\\nlight.bedroom_3 'Bedroom Light' = off;limegreen (62, 246, 31);62%\\nfan.master_bath 'Master bathroom fan' = off\\nlock.attic 'Attic Door Lock' = unlocked\\ncover.living_room 'Living Room' = closed\\nclimate.thermostat_lux_geo 'Lux Geo Wi-Fi Thermostat' = cool;Auto Low;63F;81%\\nmedia_player.sonos_kitchen 'Sonos Kitchen' = off\\nfan.study_2 'Study fan' = on\\nlight.upstairs_cinema_zwave 'Upstairs Cinema Light' = on;0%\\nlight.kitchen_bar_warm 'Kitchen Bar Warm Light' = on;darkslateblue (94, 49, 135);51%\\nlight.upstairs_master_bedroom_hue 'Upstairs Master Bedroom Hue' = off;31%\\nlight.front_basement_homekit 'Front Basement Light' = on;indianred (202, 91, 91);66%\\nswitch.conservatory_lights 'Conservatory Lights Switch' = off\\nmedia_player.sony_4k_projector 'Sony Home Cinema Projector' = idle;vol=0.32\\nlight.front_office_mqtt 'Front Office Light' = off;73%\\nlight.upstairs_washroom_zwave 'Upstairs Washroom Light' = off;72%\\nfan.attic_3 'Attic Fans' = on\"}, {'from': 'user', 'value': 'close the living room blinds'}, {'from': 'assistant', 'value': 'lowering Living Room\\n```homeassistant\\n{\"service\": \"cover.close\", \"target_device\": \"cover.living_room\"}\\n```'}]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ff754-cdba-4a77-9568-1061c386a3a5",
   "metadata": {},
   "source": [
    "# Evaluation Pipeline - Detailed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a06c8c-ec89-42c4-96e2-cc45a912c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c5ee47-6382-4f46-9822-8145486b7e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Load model & tokenizer \n",
    "model_id = \"./tinyllama-1.1b-lora-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717fa8c4-c31e-4f5b-841d-447b55ffbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & truncate\n",
    "dataset = load_dataset(\"acon96/Home-Assistant-Requests\", split=\"test[10:25]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee81c65-4dd7-4a68-bcdd-cc02dba26bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract messages\n",
    "def extract_messages(example):\n",
    "    \"\"\"\n",
    "    Extract system, user, and assistant messages from dataset example['conversations'].\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\n",
    "    user_message = \"\"\n",
    "    assistant_message = \"\"\n",
    "\n",
    "    for m in example[\"conversations\"]:\n",
    "        if m[\"from\"] == \"system\":\n",
    "            system_prompt = m[\"value\"]\n",
    "        elif m[\"from\"] == \"user\":\n",
    "            user_message = m[\"value\"]\n",
    "        elif m[\"from\"] == \"assistant\":\n",
    "            assistant_message = m[\"value\"]\n",
    "\n",
    "    return system_prompt, user_message, assistant_message\n",
    "\n",
    "\n",
    "# HELPERS \n",
    "def extract_codeblock_json(text):\n",
    "    \"\"\"Extract JSON from a triple-backtick code block, ignoring language name.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    codeblock_match = re.search(r\"```(?:\\w+)?\\s*([\\s\\S]*?)```\", text)\n",
    "    if codeblock_match:\n",
    "        candidate = codeblock_match.group(1).strip()\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def extract_entity_from_json(j):\n",
    "    \"\"\"Extract first entity (target_device) from JSON dict.\"\"\"\n",
    "    if isinstance(j, dict):\n",
    "        if \"target_device\" in j:\n",
    "            return j[\"target_device\"]\n",
    "        # Also check nested keys\n",
    "        for v in j.values():\n",
    "            if isinstance(v, dict):\n",
    "                ent = extract_entity_from_json(v)\n",
    "                if ent:\n",
    "                    return ent\n",
    "    return None\n",
    "\n",
    "\n",
    "# Extract JSON block from model output\n",
    "def extract_json_block(text):\n",
    "    match = re.search(r\"```homeassistant\\s*({.*})\\s*```\", text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0d147-94ec-4db6-af25-f445916ae9dd",
   "metadata": {},
   "source": [
    "## Semantic Textual Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c3f75b-4cfb-42a8-8ac5-aa847b6162c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample-wise Evaluation ===\n",
      "\n",
      "Sample 0 [ENTITY:✓]\n",
      " User: toggle the basement fan\n",
      " Ref text: flipping Basement state for you\n",
      "```homeassistant\n",
      "{\"service\": \"fan.toggle\", \"target_device\": \"fan.basement\"}\n",
      "```\n",
      " Pred text: [\"|>\\nswitching the fan's state as requested.\\n\", 'homeassistant\\n{\"service\": \"fan.toggle\", \"target_device\": \"fan.basement\"}\\n', '']\n",
      " Ref json: {'service': 'fan.toggle', 'target_device': 'fan.basement'} | Pred json: {\"service\": \"fan.toggle\", \"target_device\": \"fan.basement\"}\n",
      " Ref entity: fan.basement | Pred entity: fan.basement\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.51\n",
      "------------------------------------------------------------\n",
      "Sample 1 [ENTITY:✓]\n",
      " User: toggle the bedroom fan\n",
      " Ref text: flipping Bedroom state for you\n",
      "```homeassistant\n",
      "{\"service\": \"fan.toggle\", \"target_device\": \"fan.bedroom\"}\n",
      "```\n",
      " Pred text: ['|>\\ntoggling the fan now.\\n', 'homeassistant\\n{\"service\": \"fan.toggle\", \"target_device\": \"fan.bedroom\"}\\n', '']\n",
      " Ref json: {'service': 'fan.toggle', 'target_device': 'fan.bedroom'} | Pred json: {\"service\": \"fan.toggle\", \"target_device\": \"fan.bedroom\"}\n",
      " Ref entity: fan.bedroom | Pred entity: fan.bedroom\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.46\n",
      "------------------------------------------------------------\n",
      "Sample 2 [ENTITY:✓]\n",
      " User: please toggle the fan above the dining table\n",
      " Ref text: switching Dining Table Above state as requested\n",
      "```homeassistant\n",
      "{\"service\": \"fan.toggle\", \"target_device\": \"fan.dining_table_above\"}\n",
      "```\n",
      " Pred text: ['|>\\nswitching on the fan for you\\n', 'homeassistant\\n{\"service\": \"fan.turn_on\", \"target_device\": \"fan.dining_table_above\"}\\n', '']\n",
      " Ref json: {'service': 'fan.toggle', 'target_device': 'fan.dining_table_above'} | Pred json: {\"service\": \"fan.turn_on\", \"target_device\": \"fan.dining_table_above\"}\n",
      " Ref entity: fan.dining_table_above | Pred entity: fan.dining_table_above\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.44\n",
      "------------------------------------------------------------\n",
      "Sample 3 [ENTITY:✓]\n",
      " User: flip the fan in the garage\n",
      " Ref text: i'll toggle the fan's state for you.\n",
      "```homeassistant\n",
      "{\"service\": \"fan.toggle\", \"target_device\": \"fan.garage\"}\n",
      "```\n",
      " Pred text: ['|>\\nflipping Garage state\\n', 'homeassistant\\n{\"service\": \"fan.toggle\", \"target_device\": \"fan.garage\"}\\n', '']\n",
      " Ref json: {'service': 'fan.toggle', 'target_device': 'fan.garage'} | Pred json: {\"service\": \"fan.toggle\", \"target_device\": \"fan.garage\"}\n",
      " Ref entity: fan.garage | Pred entity: fan.garage\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.30\n",
      "------------------------------------------------------------\n",
      "Sample 4 [ENTITY:✗]\n",
      " User: change the status of the pool fan\n",
      " Ref text: toggling the fan now.\n",
      "```homeassistant\n",
      "{\"service\": \"fan.toggle\", \"target_device\": \"fan.pool\"}\n",
      "```\n",
      " Pred text: ['|>\\nthe pool fan is now off']\n",
      " Ref json: {'service': 'fan.toggle', 'target_device': 'fan.pool'} | Pred json: None\n",
      " Ref entity: fan.pool | Pred entity: None\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.51\n",
      "------------------------------------------------------------\n",
      "Sample 5 [ENTITY:✗]\n",
      " User: deactivate the master bedroom fan\n",
      " Ref text: turning off Bedroom Master\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_off\", \"target_device\": \"fan.bedroom_master\"}\n",
      "```\n",
      " Pred text: ['|>\\nturning off Master Bedroom Lights Switch\\n', 'homeassistant\\n{\"service\": \"switch.turn_off\", \"target_device\": \"switch.master_bedroom_lights\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_off', 'target_device': 'fan.bedroom_master'} | Pred json: {\"service\": \"switch.turn_off\", \"target_device\": \"switch.master_bedroom_lights\"}\n",
      " Ref entity: fan.bedroom_master | Pred entity: switch.master_bedroom_lights\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.57\n",
      "------------------------------------------------------------\n",
      "Sample 6 [ENTITY:✓]\n",
      " User: switch off the garage fan\n",
      " Ref text: certainly, stopping Garage\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_off\", \"target_device\": \"fan.garage\"}\n",
      "```\n",
      " Pred text: ['|>\\ndeactivating Garage\\n', 'homeassistant\\n{\"service\": \"fan.turn_off\", \"target_device\": \"fan.garage\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_off', 'target_device': 'fan.garage'} | Pred json: {\"service\": \"fan.turn_off\", \"target_device\": \"fan.garage\"}\n",
      " Ref entity: fan.garage | Pred entity: fan.garage\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.57\n",
      "------------------------------------------------------------\n",
      "Sample 7 [ENTITY:✓]\n",
      " User: turn off the living room fan\n",
      " Ref text: deactivating Living Room as requested\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_off\", \"target_device\": \"fan.living_room\"}\n",
      "```\n",
      " Pred text: ['|>\\nsure, turning off Living Room\\n', 'homeassistant\\n{\"service\": \"fan.turn_off\", \"target_device\": \"fan.living_room\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_off', 'target_device': 'fan.living_room'} | Pred json: {\"service\": \"fan.turn_off\", \"target_device\": \"fan.living_room\"}\n",
      " Ref entity: fan.living_room | Pred entity: fan.living_room\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.58\n",
      "------------------------------------------------------------\n",
      "Sample 8 [ENTITY:✗]\n",
      " User: could you disable the office fan\n",
      " Ref text: stopping Office for you\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_off\", \"target_device\": \"fan.office\"}\n",
      "```\n",
      " Pred text: ['|>\\nsure, stopping office blinds.\\n', 'homeassistant\\n{\"service\": \"vacuum.stop\", \"target_device\": \"vacuum.under_bed_cleaner\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_off', 'target_device': 'fan.office'} | Pred json: {\"service\": \"vacuum.stop\", \"target_device\": \"vacuum.under_bed_cleaner\"}\n",
      " Ref entity: fan.office | Pred entity: vacuum.under_bed_cleaner\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.36\n",
      "------------------------------------------------------------\n",
      "Sample 9 [ENTITY:✓]\n",
      " User: activate the bathroom fan\n",
      " Ref text: starting Bathroom\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_on\", \"target_device\": \"fan.bathroom\"}\n",
      "```\n",
      " Pred text: ['|>\\nturning on the fan for you\\n', 'homeassistant\\n{\"service\": \"fan.turn_on\", \"target_device\": \"fan.bathroom\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_on', 'target_device': 'fan.bathroom'} | Pred json: {\"service\": \"fan.turn_on\", \"target_device\": \"fan.bathroom\"}\n",
      " Ref entity: fan.bathroom | Pred entity: fan.bathroom\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.39\n",
      "------------------------------------------------------------\n",
      "Sample 10 [ENTITY:✓]\n",
      " User: turn on the bathroom fan\n",
      " Ref text: sure, turning on the fan now.\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_on\", \"target_device\": \"fan.bathroom\"}\n",
      "```\n",
      " Pred text: [\"|>\\ni'll start the fan for you.\\n\", 'homeassistant\\n{\"service\": \"fan.turn_on\", \"target_device\": \"fan.bathroom\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_on', 'target_device': 'fan.bathroom'} | Pred json: {\"service\": \"fan.turn_on\", \"target_device\": \"fan.bathroom\"}\n",
      " Ref entity: fan.bathroom | Pred entity: fan.bathroom\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.35\n",
      "------------------------------------------------------------\n",
      "Sample 11 [ENTITY:✓]\n",
      " User: please switch on the dining area fan\n",
      " Ref text: i'll get the fan going for you.\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_on\", \"target_device\": \"fan.dining_area\"}\n",
      "```\n",
      " Pred text: ['|>\\nactivating the fan for you\\n', 'homeassistant\\n{\"service\": \"fan.turn_on\", \"target_device\": \"fan.dining_area\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_on', 'target_device': 'fan.dining_area'} | Pred json: {\"service\": \"fan.turn_on\", \"target_device\": \"fan.dining_area\"}\n",
      " Ref entity: fan.dining_area | Pred entity: fan.dining_area\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.43\n",
      "------------------------------------------------------------\n",
      "Sample 12 [ENTITY:✓]\n",
      " User: enable the hallway fan\n",
      " Ref text: i'll get the fan going for you.\n",
      "```homeassistant\n",
      "{\"service\": \"fan.turn_on\", \"target_device\": \"fan.hallway\"}\n",
      "```\n",
      " Pred text: ['|>\\nswitching on Hallway for you\\n', 'homeassistant\\n{\"service\": \"fan.turn_on\", \"target_device\": \"fan.hallway\"}\\n', '']\n",
      " Ref json: {'service': 'fan.turn_on', 'target_device': 'fan.hallway'} | Pred json: {\"service\": \"fan.turn_on\", \"target_device\": \"fan.hallway\"}\n",
      " Ref entity: fan.hallway | Pred entity: fan.hallway\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.31\n",
      "------------------------------------------------------------\n",
      "Sample 13 [ENTITY:✓]\n",
      " User: deactivate the bike storage garage\n",
      " Ref text: closing Bike Storage\n",
      "```homeassistant\n",
      "{\"service\": \"cover.close\", \"target_device\": \"cover.bike_storage\"}\n",
      "```\n",
      " Pred text: ['|>\\ndeactivating bike storage garage\\n', 'homeassistant\\n{\"service\": \"cover.stop\", \"target_device\": \"cover.bike_storage\"}\\n', '']\n",
      " Ref json: {'service': 'cover.close', 'target_device': 'cover.bike_storage'} | Pred json: {\"service\": \"cover.stop\", \"target_device\": \"cover.bike_storage\"}\n",
      " Ref entity: cover.bike_storage | Pred entity: cover.bike_storage\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.49\n",
      "------------------------------------------------------------\n",
      "Sample 14 [ENTITY:✗]\n",
      " User: make sure the one car garage is closed\n",
      " Ref text: sure, closing the garage door.\n",
      "```homeassistant\n",
      "{\"service\": \"cover.close\", \"target_device\": \"cover.one_car\"}\n",
      "```\n",
      " Pred text: ['|>\\nthe one car garage is currently closed']\n",
      " Ref json: {'service': 'cover.close', 'target_device': 'cover.one_car'} | Pred json: None\n",
      " Ref entity: cover.one_car | Pred entity: None\n",
      "Similarity evaluation\n",
      "\n",
      "Semantic similarity: 0.55\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Overall Accuracy ===\n",
      "Entity Accuracy: 11/15 (73.33%)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model for semantic textual similarity\n",
    "sts_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Similarity evaluation\n",
    "def semantic_similarity(ref_text, pred_text):\n",
    "    # Generate embeddings for both sentences\n",
    "    emb_ref = sts_model.encode(ref_text, convert_to_tensor=True)\n",
    "    emb_pred = sts_model.encode(pred_text, convert_to_tensor=True)\n",
    "    # Compute cosine similarity - ranges from -1 (opposite) to 1 (identical)\n",
    "    score = util.pytorch_cos_sim(emb_ref, emb_pred).item()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Counters for accuracy\n",
    "total_samples = len(dataset)\n",
    "json_correct = 0\n",
    "entity_correct = 0\n",
    "\n",
    "print(\"\\n=== Sample-wise Evaluation ===\\n\")\n",
    "for idx, example in enumerate(dataset):\n",
    "    system_prompt, user_message, reference_text = extract_messages(example)\n",
    "    ref_json = extract_codeblock_json(reference_text)\n",
    "    ref_entity = extract_entity_from_json(ref_json) if ref_json else None\n",
    "\n",
    "    # Build chat prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Keep only assistant's part if needed\n",
    "    if \"assistant\" in decoded:\n",
    "        decoded = decoded.split(\"assistant\", 1)[-1].strip()\n",
    "\n",
    "    # Extract predicted JSON\n",
    "    pred_json = extract_json_block(decoded)\n",
    "\n",
    "    # Extract predicted entity\n",
    "    pred_entity = None\n",
    "    if pred_json:\n",
    "        try:\n",
    "            pred_dict = json.loads(pred_json)\n",
    "            pred_entity = pred_dict.get(\"target_device\", None)\n",
    "        except json.JSONDecodeError:\n",
    "            pred_entity = None\n",
    "\n",
    "    pred_text = decoded.split(\"```\")\n",
    "    # Fix: ensure pred_text is a single string\n",
    "    pred_text_str = pred_text[0].strip() if isinstance(pred_text, list) else str(pred_text).strip()\n",
    "\n",
    "    # Compare results\n",
    "    json_match_flag = (pred_json == json.dumps(ref_json)) if ref_json else False\n",
    "    entity_match_flag = (pred_entity == ref_entity) if ref_entity else False\n",
    "\n",
    "    # Update counters\n",
    "    if json_match_flag:\n",
    "        json_correct += 1\n",
    "    if entity_match_flag:\n",
    "        entity_correct += 1\n",
    "\n",
    "    # Per-sample print\n",
    "    print(f\"Sample {idx} [ENTITY:{'✓' if entity_match_flag else '✗'}]\")\n",
    "    print(f\" User: {user_message}\")\n",
    "    print(f\" Ref text: {reference_text}\")\n",
    "    print(f\" Pred text: {pred_text}\")\n",
    "    print(f\" Ref json: {ref_json} | Pred json: {pred_json}\")\n",
    "    print(f\" Ref entity: {ref_entity} | Pred entity: {pred_entity}\")\n",
    "    print(\"Similarity evaluation\\n\")\n",
    "    similarity_score = semantic_similarity(reference_text.strip(), pred_text_str)\n",
    "    print(f\"Semantic similarity: {similarity_score:.2f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Final accuracy results\n",
    "json_accuracy = json_correct / total_samples * 100\n",
    "entity_accuracy = entity_correct / total_samples * 100\n",
    "\n",
    "print(\"\\n=== Overall Accuracy ===\")\n",
    "#print(f\"JSON Accuracy: {json_correct}/{total_samples} ({json_accuracy:.2f}%)\")\n",
    "print(f\"Entity Accuracy: {entity_correct}/{total_samples} ({entity_accuracy:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2329f1e-f79a-4b65-b62a-aeae1bd7057f",
   "metadata": {},
   "source": [
    "## Evaluation using BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b96345-cdf8-4dbe-9f1e-92e5d75af5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bert-score accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b493cb6-bfe3-4e36-a16d-afbe3f9eb50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample-wise Evaluation ===\n",
      "\n",
      "Sample 0 [ENTITY:✓]\n",
      " User: please lock the guest room door.\n",
      " Ref text: locking Guest Room Door\n",
      "```homeassistant\n",
      "{\"service\": \"lock.lock\", \"target_device\": \"lock.guest_room_door\"}\n",
      "```\n",
      " Pred text: |>\n",
      "locking Guest Room Door\n",
      " Ref json: {'service': 'lock.lock', 'target_device': 'lock.guest_room_door'} | Pred json: {\"service\": \"lock.lock\", \"target_device\": \"lock.guest_room_door\"}\n",
      " Ref entity: lock.guest_room_door | Pred entity: lock.guest_room_door\n",
      "------------------------------------------------------------\n",
      "Sample 1 [ENTITY:✓]\n",
      " User: attic door needs locking.\n",
      " Ref text: locking the door for you.\n",
      "```homeassistant\n",
      "{\"service\": \"lock.lock\", \"target_device\": \"lock.attic_door\"}\n",
      "```\n",
      " Pred text: |>\n",
      "attic door lock is now in process of being locked\n",
      " Ref json: {'service': 'lock.lock', 'target_device': 'lock.attic_door'} | Pred json: {\"service\": \"lock.lock\", \"target_device\": \"lock.attic_door\"}\n",
      " Ref entity: lock.attic_door | Pred entity: lock.attic_door\n",
      "------------------------------------------------------------\n",
      "Sample 2 [ENTITY:✗]\n",
      " User: carport gate needs to be locked.\n",
      " Ref text: locking Carport Gate\n",
      "```homeassistant\n",
      "{\"service\": \"lock.lock\", \"target_device\": \"lock.carport_gate\"}\n",
      "```\n",
      " Pred text: |>\n",
      "carport gate has been locked for you.\n",
      " Ref json: {'service': 'lock.lock', 'target_device': 'lock.carport_gate'} | Pred json: {\"service\": \"cover.close\", \"target_device\": \"cover.spare\"}\n",
      " Ref entity: lock.carport_gate | Pred entity: cover.spare\n",
      "------------------------------------------------------------\n",
      "Sample 3 [ENTITY:✓]\n",
      " User: lock the front porch door.\n",
      " Ref text: engaging lock on Front Porch Door\n",
      "```homeassistant\n",
      "{\"service\": \"lock.lock\", \"target_device\": \"lock.front_porch_door\"}\n",
      "```\n",
      " Pred text: |>\n",
      "locking the door as requested.\n",
      " Ref json: {'service': 'lock.lock', 'target_device': 'lock.front_porch_door'} | Pred json: {\"service\": \"lock.lock\", \"target_device\": \"lock.front_porch_door\"}\n",
      " Ref entity: lock.front_porch_door | Pred entity: lock.front_porch_door\n",
      "------------------------------------------------------------\n",
      "Sample 4 [ENTITY:✓]\n",
      " User: disengage the lock on the bike storage\n",
      " Ref text: unlocking Bike Storage\n",
      "```homeassistant\n",
      "{\"service\": \"lock.unlock\", \"target_device\": \"lock.bike_storage\"}\n",
      "```\n",
      " Pred text: |>\n",
      "unlocking bike storage now\n",
      " Ref json: {'service': 'lock.unlock', 'target_device': 'lock.bike_storage'} | Pred json: {\"service\": \"lock.unlock\", \"target_device\": \"lock.bike_storage\"}\n",
      " Ref entity: lock.bike_storage | Pred entity: lock.bike_storage\n",
      "------------------------------------------------------------\n",
      "Sample 5 [ENTITY:✓]\n",
      " User: can you unlock the fire escape?\n",
      " Ref text: unlocking the door as you requested.\n",
      "```homeassistant\n",
      "{\"service\": \"lock.unlock\", \"target_device\": \"lock.fire_escape\"}\n",
      "```\n",
      " Pred text: |>\n",
      "i'll unlock the lock for you.\n",
      " Ref json: {'service': 'lock.unlock', 'target_device': 'lock.fire_escape'} | Pred json: {\"service\": \"lock.unlock\", \"target_device\": \"lock.fire_escape\"}\n",
      " Ref entity: lock.fire_escape | Pred entity: lock.fire_escape\n",
      "------------------------------------------------------------\n",
      "Sample 6 [ENTITY:✓]\n",
      " User: unlock the music room, please.\n",
      " Ref text: unsecuring Music Room for you\n",
      "```homeassistant\n",
      "{\"service\": \"lock.unlock\", \"target_device\": \"lock.music_room\"}\n",
      "```\n",
      " Pred text: |>\n",
      "unlocking Music Room\n",
      " Ref json: {'service': 'lock.unlock', 'target_device': 'lock.music_room'} | Pred json: {\"service\": \"lock.unlock\", \"target_device\": \"lock.music_room\"}\n",
      " Ref entity: lock.music_room | Pred entity: lock.music_room\n",
      "------------------------------------------------------------\n",
      "Sample 7 [ENTITY:✓]\n",
      " User: skip to the next track in the living room\n",
      " Ref text: advancing to the next song on Living Room.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.media_next_track\", \"target_device\": \"media_player.living_room\"}\n",
      "```\n",
      " Pred text: |>\n",
      "going to skip to the next track on the media player.\n",
      " Ref json: {'service': 'media_player.media_next_track', 'target_device': 'media_player.living_room'} | Pred json: {\"service\": \"media_player.media_next_track\", \"target_device\": \"media_player.living_room\"}\n",
      " Ref entity: media_player.living_room | Pred entity: media_player.living_room\n",
      "------------------------------------------------------------\n",
      "Sample 8 [ENTITY:✓]\n",
      " User: pause the radio in the laundry room.\n",
      " Ref text: holding playback on Laundry Room Radio.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.media_pause\", \"target_device\": \"media_player.laundry_room_radio\"}\n",
      "```\n",
      " Pred text: |>\n",
      "sure, stopping the radio.\n",
      " Ref json: {'service': 'media_player.media_pause', 'target_device': 'media_player.laundry_room_radio'} | Pred json: {\"service\": \"media_player.media_pause\", \"target_device\": \"media_player.laundry_room_radio\"}\n",
      " Ref entity: media_player.laundry_room_radio | Pred entity: media_player.laundry_room_radio\n",
      "------------------------------------------------------------\n",
      "Sample 9 [ENTITY:✓]\n",
      " User: play the stereo in the sunroom.\n",
      " Ref text: i'll start playing the media for you.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.media_play\", \"target_device\": \"media_player.sunroom_stereo\"}\n",
      "```\n",
      " Pred text: |>\n",
      "starting media playback on sunroom stereo.\n",
      " Ref json: {'service': 'media_player.media_play', 'target_device': 'media_player.sunroom_stereo'} | Pred json: {\"service\": \"media_player.media_play\", \"target_device\": \"media_player.sunroom_stereo\"}\n",
      " Ref entity: media_player.sunroom_stereo | Pred entity: media_player.sunroom_stereo\n",
      "------------------------------------------------------------\n",
      "Sample 10 [ENTITY:✓]\n",
      " User: start the storyteller in the kids' room.\n",
      " Ref text: playing media on Kids Room Storyteller.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.media_play\", \"target_device\": \"media_player.kids_room_storyteller\"}\n",
      "```\n",
      " Pred text: |>\n",
      "starting the media on Kids' Room Storyteller.\n",
      " Ref json: {'service': 'media_player.media_play', 'target_device': 'media_player.kids_room_storyteller'} | Pred json: {\"service\": \"media_player.media_play\", \"target_device\": \"media_player.kids_room_storyteller\"}\n",
      " Ref entity: media_player.kids_room_storyteller | Pred entity: media_player.kids_room_storyteller\n",
      "------------------------------------------------------------\n",
      "Sample 11 [ENTITY:✓]\n",
      " User: play the jukebox in the cellar.\n",
      " Ref text: playing Cellar Jukebox now.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.media_play\", \"target_device\": \"media_player.cellar_jukebox\"}\n",
      "```\n",
      " Pred text: |>\n",
      "starting playback on Cellar Jukebox.\n",
      " Ref json: {'service': 'media_player.media_play', 'target_device': 'media_player.cellar_jukebox'} | Pred json: {\"service\": \"media_player.media_play\", \"target_device\": \"media_player.cellar_jukebox\"}\n",
      " Ref entity: media_player.cellar_jukebox | Pred entity: media_player.cellar_jukebox\n",
      "------------------------------------------------------------\n",
      "Sample 12 [ENTITY:✓]\n",
      " User: switch off the lounge entertainment center.\n",
      " Ref text: i'll switch off the media player.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.turn_off\", \"target_device\": \"media_player.lounge_entertainment\"}\n",
      "```\n",
      " Pred text: |>\n",
      "turning off Lounge Entertainment\n",
      " Ref json: {'service': 'media_player.turn_off', 'target_device': 'media_player.lounge_entertainment'} | Pred json: {\"service\": \"media_player.turn_off\", \"target_device\": \"media_player.lounge_entertainment\"}\n",
      " Ref entity: media_player.lounge_entertainment | Pred entity: media_player.lounge_entertainment\n",
      "------------------------------------------------------------\n",
      "Sample 13 [ENTITY:✓]\n",
      " User: turn off the echo in the entryway.\n",
      " Ref text: sure, deactivating the media player.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.turn_off\", \"target_device\": \"media_player.entryway_echo\"}\n",
      "```\n",
      " Pred text: |>\n",
      "sure, turning off the media player.\n",
      " Ref json: {'service': 'media_player.turn_off', 'target_device': 'media_player.entryway_echo'} | Pred json: {\"service\": \"media_player.media_stop\", \"target_device\": \"media_player.entryway_echo\"}\n",
      " Ref entity: media_player.entryway_echo | Pred entity: media_player.entryway_echo\n",
      "------------------------------------------------------------\n",
      "Sample 14 [ENTITY:✓]\n",
      " User: power off the speakers in the wine cellar.\n",
      " Ref text: turning off the media player as requested.\n",
      "```homeassistant\n",
      "{\"service\": \"media_player.turn_off\", \"target_device\": \"media_player.wine_cellar_speakers\"}\n",
      "```\n",
      " Pred text: |>\n",
      "switching off Wine Cellar Speakers.\n",
      " Ref json: {'service': 'media_player.turn_off', 'target_device': 'media_player.wine_cellar_speakers'} | Pred json: {\"service\": \"media_player.turn_off\", \"target_device\": \"media_player.wine_cellar_speakers\"}\n",
      " Ref entity: media_player.wine_cellar_speakers | Pred entity: media_player.wine_cellar_speakers\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Overall Accuracy ===\n",
      "Entity Accuracy: 14/15 (93.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6099c9570b3a481c911ec8c6c2860f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399dce9dbee146fc858b3373d1baffe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.12 seconds, 127.78 sentences/sec\n",
      "\n",
      "=== BERTScore Results ===\n",
      "Precision: 0.8575\n",
      "Recall:    0.7897\n",
      "F1 Score:  0.8221\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from bert_score import score\n",
    "\n",
    "# Load model & tokenizer \n",
    "model_id = \"./tinyllama-1.1b-lora-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load dataset & truncate\n",
    "dataset = load_dataset(\"acon96/Home-Assistant-Requests\", split=\"test[50:65]\")\n",
    "\n",
    "# Extract messages\n",
    "def extract_messages(example):\n",
    "    system_prompt, user_message, assistant_message = \"\", \"\", \"\"\n",
    "    for m in example[\"conversations\"]:\n",
    "        if m[\"from\"] == \"system\":\n",
    "            system_prompt = m[\"value\"]\n",
    "        elif m[\"from\"] == \"user\":\n",
    "            user_message = m[\"value\"]\n",
    "        elif m[\"from\"] == \"assistant\":\n",
    "            assistant_message = m[\"value\"]\n",
    "    return system_prompt, user_message, assistant_message\n",
    "\n",
    "# HELPERS \n",
    "def extract_codeblock_json(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    codeblock_match = re.search(r\"```(?:\\w+)?\\s*([\\s\\S]*?)```\", text)\n",
    "    if codeblock_match:\n",
    "        candidate = codeblock_match.group(1).strip()\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def extract_entity_from_json(j):\n",
    "    if isinstance(j, dict):\n",
    "        if \"target_device\" in j:\n",
    "            return j[\"target_device\"]\n",
    "        for v in j.values():\n",
    "            if isinstance(v, dict):\n",
    "                ent = extract_entity_from_json(v)\n",
    "                if ent:\n",
    "                    return ent\n",
    "    return None\n",
    "\n",
    "def extract_json_block(text):\n",
    "    match = re.search(r\"```homeassistant\\s*({.*})\\s*```\", text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "# Counters for accuracy\n",
    "total_samples = len(dataset)\n",
    "json_correct = 0\n",
    "entity_correct = 0\n",
    "\n",
    "# Collect refs & preds for BERTScore\n",
    "all_refs = []\n",
    "all_preds = []\n",
    "\n",
    "print(\"\\n=== Sample-wise Evaluation ===\\n\")\n",
    "for idx, example in enumerate(dataset):\n",
    "    system_prompt, user_message, reference_text = extract_messages(example)\n",
    "    ref_json = extract_codeblock_json(reference_text)\n",
    "    ref_entity = extract_entity_from_json(ref_json) if ref_json else None\n",
    "\n",
    "    # Build chat prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"assistant\" in decoded:\n",
    "        decoded = decoded.split(\"assistant\", 1)[-1].strip()\n",
    "\n",
    "    # Extract predicted JSON\n",
    "    pred_json = extract_json_block(decoded)\n",
    "\n",
    "    pred_entity = None\n",
    "    if pred_json:\n",
    "        try:\n",
    "            pred_dict = json.loads(pred_json)\n",
    "            pred_entity = pred_dict.get(\"target_device\", None)\n",
    "        except json.JSONDecodeError:\n",
    "            pred_entity = None\n",
    "\n",
    "    # Text outside JSON (natural language response)\n",
    "    pred_text = decoded.split(\"```\")\n",
    "    pred_text_str = pred_text[0].strip() if isinstance(pred_text, list) else str(pred_text).strip()\n",
    "\n",
    "    # Compare results\n",
    "    json_match_flag = (pred_json == json.dumps(ref_json)) if ref_json else False\n",
    "    entity_match_flag = (pred_entity == ref_entity) if ref_entity else False\n",
    "\n",
    "    if json_match_flag:\n",
    "        json_correct += 1\n",
    "    if entity_match_flag:\n",
    "        entity_correct += 1\n",
    "\n",
    "    # Collect for BERTScore\n",
    "    all_refs.append(reference_text.strip())\n",
    "    all_preds.append(pred_text_str)\n",
    "\n",
    "    print(f\"Sample {idx} [ENTITY:{'✓' if entity_match_flag else '✗'}]\")\n",
    "    print(f\" User: {user_message}\")\n",
    "    print(f\" Ref text: {reference_text}\")\n",
    "    print(f\" Pred text: {pred_text_str}\")\n",
    "    print(f\" Ref json: {ref_json} | Pred json: {pred_json}\")\n",
    "    print(f\" Ref entity: {ref_entity} | Pred entity: {pred_entity}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# === Final metrics ===\n",
    "json_accuracy = json_correct / total_samples * 100\n",
    "entity_accuracy = entity_correct / total_samples * 100\n",
    "\n",
    "print(\"\\n=== Overall Accuracy ===\")\n",
    "print(f\"Entity Accuracy: {entity_correct}/{total_samples} ({entity_accuracy:.2f}%)\")\n",
    "\n",
    "# === BERTScore ===\n",
    "P, R, F1 = score(all_preds, all_refs, lang=\"en\", verbose=True)\n",
    "print(\"\\n=== BERTScore Results ===\")\n",
    "print(f\"Precision: {P.mean().item():.4f}\")\n",
    "print(f\"Recall:    {R.mean().item():.4f}\")\n",
    "print(f\"F1 Score:  {F1.mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbb729-00e5-4c43-bdfe-b8207e8d227c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
